@thesis{castro2015deteccion,
  title={Humor Detection in Spanish Tweets (`Detección de humor en textos en español')},
  author={\underline{Castro, Santiago} and Cubero, Matías},
  institution={Universidad de la República},
  type={Bachelor's thesis},
  year={2015}
}

@inproceedings{castro2016joke,
  title={Is This a Joke? Detecting Humor in Spanish Tweets},
  author={\underline{Castro, Santiago} and Cubero, Matías and Garat, Diego and Moncecchi, Guillermo},
  booktitle={Ibero-American Conference on Artificial Intelligence (IBERAMIA)},
  pages={139--150},
  year={2016},
  note={\color{red}{Best Paper Award \nth{2} place}}
}

@misc{castro2016esto,
  title={Is This a Joke? Detecting Humor in Tweets (``¿Esto es un chiste? Detección de humor en tuits'')},
  author={\underline{Castro, Santiago}},
  editor={9º Foro de Lenguas de ANEP},
  pages={115--126},
  year={2016}
}

@incollection{rosa2017retuyt,
  title={RETUYT in TASS 2017: Sentiment Analysis for Spanish Tweets using SVM and CNN},
  author={Rosá, Aiala and Chiruzzo, Luis and Etcheverry, Mathias and \underline{Santiago Castro}},
  booktitle={Workshop on Semantic Analysis at SEPLN (TASS)},
  year={2017}
}

@incollection{castro2018crowd,
  title={A crowd-annotated spanish corpus for humor analysis},
  author={\underline{Castro, Santiago} and Chiruzzo, Luis and Rosá, Aiala and Garat, Diego and Moncecchi, Guillermo},
  booktitle={Sixth International Workshop on Natural Language Processing for Social Media (SocialNLP)},
  pages={7--11},
  year={2018}
}

@incollection{castro2018high,
  title={A High Coverage Method for Automatic False Friends Detection for Spanish and Portuguese},
  author={\underline{Castro, Santiago} and Bonanata, Jairo and Rosá, Aiala},
  booktitle={Fifth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
  pages={29--36},
  year={2018}
}

@incollection{castro2018overview,
  title={Overview of the HAHA Task: Humor Analysis based on Human Annotation at IberEval 2018
},
  author={\underline{Castro, Santiago} and Chiruzzo, Luis and Rosá, Aiala},
  booktitle={Third Workshop on Evaluation of Human Language Technologies for Iberian Languages (IberEval)},
  volume={2150},
  pages={187--194},
  year={2018}
}

@inproceedings{mustard,
    title = "Towards Multimodal Sarcasm Detection (An  \_Obviously\_ Perfect Paper)",
    author = "\underline{Castro, Santiago}  and
      Hazarika, Devamanyu  and
      P{\'e}rez-Rosas, Ver{\'o}nica  and
      Zimmermann, Roger  and
      Mihalcea, Rada  and
      Poria, Soujanya",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (ACL)",
    year = "2019"
}

@incollection{haha2019,
    author      = "Chiruzzo, Luis and \underline{Santiago Castro} and Etcheverry, Mathias and Garat, Diego and Prada, Juan Jos{\'e} and Ros{\'a}, Aiala",
    title       = "{Overview of HAHA at IberLEF 2019: Humor Analysis based on Human Annotation}",
    booktitle   = "{Proceedings of the Iberian Languages Evaluation Forum (IberLEF)}",
    year        = "2019",
}

@inproceedings{castro-etal-2020-lifeqa,
    title = "{L}ife{QA}: A Real-life Dataset for Video Question Answering",
    author = "\underline{Castro, Santiago}  and
      Azab, Mahmoud  and
      Stroud, Jonathan  and
      Noujaim, Cristina  and
      Wang, Ruoyao  and
      Deng, Jia  and
      Mihalcea, Rada",
    booktitle = "Proceedings of The 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://www.aclweb.org/anthology/2020.lrec-1.536",
    pages = "4352--4358",
    abstract = "We introduce LifeQA, a benchmark dataset for video question answering that focuses on day-to-day real-life situations. Current video question answering datasets consist of movies and TV shows. However, it is well-known that these visual domains are not representative of our day-to-day lives. Movies and TV shows, for example, benefit from professional camera movements, clean editing, crisp audio recordings, and scripted dialog between professional actors. While these domains provide a large amount of data for training models, their properties make them unsuitable for testing real-life question answering systems. Our dataset, by contrast, consists of video clips that represent only real-life scenarios. We collect 275 such video clips and over 2.3k multiple-choice questions. In this paper, we analyze the challenging but realistic aspects of LifeQA, and we apply several state-of-the-art video question answering models to provide benchmarks for future research. The full dataset is publicly available at https://lit.eecs.umich.edu/lifeqa/.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{chiruzzo-etal-2020-haha,
    title = "{HAHA} 2019 Dataset: A Corpus for Humor Analysis in {S}panish",
    author = "Chiruzzo, Luis  and
      \underline{Santiago Castro}  and
      Ros{\'a}, Aiala",
    booktitle = "Proceedings of The 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://www.aclweb.org/anthology/2020.lrec-1.628",
    pages = "5106--5112",
    abstract = "This paper presents the development of a corpus of 30,000 Spanish tweets that were crowd-annotated with humor value and funniness score. The corpus contains approximately 38.6{\%} of humorous tweets with an average score of 2.04 in a scale from 1 to 5 for the humorous tweets. The corpus has been used in an automatic humor recognition and analysis competition, obtaining encouraging results from the participants.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}
